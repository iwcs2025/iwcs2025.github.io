Keynotes
====

<br>

Oana-Maria Camburu (Imperial College London)
----
<img style="display: block;margin: 25px;max-width: 30%;" src="photos/OMCamburu.png" align="left">

Oana-Maria Camburu is an Assistant Professor in the Department of Computing at Imperial College London. Prior to that, she was a Principal Research Fellow in the Department of Computer Science at the University College London, holding an Early Career Leverhulme Fellowship. Oana was also a postdoc at the University of Oxford, from where she obtained her PhD in "Explaining Deep Neural Networks". Her main research interests lie in explainability for deep learning models and AI safety and alignment. 

<br>
<br>
<br>

**Title**: _Thoughts You Can Trust? Evaluating the Faithfulness of  Model-Generated Explanations and Their Effects on Human Performance_

**Abstract**: Large Language Models (LLMs) can readily generate natural language explanations—or chain-of-thoughts (CoTs)—to justify their outputs. In this talk, I will first introduce methods for evaluating whether such explanations faithfully reflect the decision-making processes of the models that produce them. Second, I present the results of a user study involving 85 clinicians and medical students diagnosing chest X-rays. The study compares the effectiveness of natural language explanations, saliency maps, and their combination in supporting clinical decision-making.


<br>

Alexander Koller (Saarland University)
----

<div>
<img style="display: block;margin: 25px;max-width: 30%;" src="photos/koller-small.jpeg" align="left">
<br>

Alexander Koller is a Professor of Computational Linguistics at
Saarland University in Saarbrücken, Germany. His research interests
include planning and reasoning with LLMs, syntactic and semantic
processing, natural language generation, and dialogue systems. He is
particularly interested in neurosymbolic models that bring together
principled linguistic modeling and correctness guarantees with the
coverage and robustness of neural approaches. Alexander received his
PhD from Saarland University and was previously a postdoc at Columbia
University and the University of Edinburgh, faculty at the University
of Potsdam, and Visiting Senior Research Scientist at the Allen
Institute for AI.
</div>



<br>

Denis Paperno (Utrecht University)
---

<div>
<img style="display: block;margin: 25px;max-width: 30%;" src="photos/denis_on_green.jpg" align="left">
<br>

Denis Paperno is assistant professor of computational linguistics at Utrecht University. He received a PhD in Linguistics from the University of California Los Angeles, and subsequently worked at the University of Trento (CLIC lab, Rovereto) as a postdoc and at the Loria lab (Nancy) as a CNRS researcher. Denis has published extensively in the fields of semantics, language model evaluation, and vector space representations of meaning. His research contributions include work on compositionality in computational models of semantics, visual grounding, and representation probing.
</div>


<br>
<br>
<br>



